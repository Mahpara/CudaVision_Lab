{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment06_VAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b4da4e239fe41c7994b5f8d2cee6ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0dda09f71a74859b74037bd4ebbb7c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a13e783590e4faea795b6bf1d8519da",
              "IPY_MODEL_117a4330ff1047ee80b5ef0e5afe2ac8"
            ]
          }
        },
        "a0dda09f71a74859b74037bd4ebbb7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a13e783590e4faea795b6bf1d8519da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_30331d8efd95425c9568b242bced8ebf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71489742e0cd4e7bab5162a6ae477e33"
          }
        },
        "117a4330ff1047ee80b5ef0e5afe2ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e952e9435d5548dbad5734ebeebd8c09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:19&lt;00:00, 54048546.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7eefcca3930f453eab55d15379f46412"
          }
        },
        "30331d8efd95425c9568b242bced8ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71489742e0cd4e7bab5162a6ae477e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e952e9435d5548dbad5734ebeebd8c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7eefcca3930f453eab55d15379f46412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPjxIDnzpr3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils as utils\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSnTD6nppz4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "8b4da4e239fe41c7994b5f8d2cee6ec6",
            "a0dda09f71a74859b74037bd4ebbb7c8",
            "0a13e783590e4faea795b6bf1d8519da",
            "117a4330ff1047ee80b5ef0e5afe2ac8",
            "30331d8efd95425c9568b242bced8ebf",
            "71489742e0cd4e7bab5162a6ae477e33",
            "e952e9435d5548dbad5734ebeebd8c09",
            "7eefcca3930f453eab55d15379f46412"
          ]
        },
        "outputId": "75a663c1-4066-4d66-8fbf-ae17e478a96f"
      },
      "source": [
        "batch_size =100\n",
        "\n",
        "\n",
        "# Download Data\n",
        "cifar_train = dset.CIFAR10(\"./\",train=True,transform=transforms.ToTensor(),target_transform=None,download=True)\n",
        "cifar_test= dset.CIFAR10(\"./\",train=False,transform=transforms.ToTensor(),target_transform=None,download=True)\n",
        "\n",
        "#mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "#mnist_test  = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "\n",
        "# Set Data Loader(input pipeline)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=cifar_train,batch_size=batch_size,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=cifar_test,batch_size=batch_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b4da4e239fe41c7994b5f8d2cee6ec6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7C6Wpbrp2XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class UnFlatten(nn.Module):\n",
        "    def forward(self, input, size=1024):\n",
        "        return input.view(input.size(0), size, 1, 1)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_channels=3, h_dim=1024, z_dim=32):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2,padding=1),\n",
        "            nn.ReLU(),\n",
        "            Flatten()\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            UnFlatten(),\n",
        "            nn.ConvTranspose2d(h_dim, 128, kernel_size=4, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=6, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_().cuda()\n",
        "        # return torch.normal(mu, std)\n",
        "        esp = torch.randn(*mu.size()).cuda()\n",
        "        z = mu + std * esp\n",
        "        return z\n",
        "    \n",
        "    def bottleneck(self, h):\n",
        "        mu, logvar = self.fc1(h), self.fc2(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return z, mu, logvar\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z, mu, logvar = self.bottleneck(h)\n",
        "        return z, mu, logvar\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.fc3(z)\n",
        "        z = self.decoder(z)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        z, mu, logvar = self.encode(x)\n",
        "        z = self.decode(z)\n",
        "        return z, mu, logvar"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xxHtfE8qcmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build model\n",
        "vae = VAE()\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NYpxcGpqnzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(vae.parameters())\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum') #x.view(-1, 1024)\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izJzfSn2qymv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, mu, log_var = vae(data)\n",
        "        loss = loss_function(recon_batch, data, mu, log_var)\n",
        "        \n",
        "        \n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "def test():\n",
        "    vae.eval()\n",
        "    test_loss= 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "            recon, mu, log_var = vae(data)\n",
        "            \n",
        "            # sum up batch loss\n",
        "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HVaT42pq66j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "892911bd-7246-49b0-9efa-7492455e9d80"
      },
      "source": [
        "for epoch in range(1, 51):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1845.835625\n",
            "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 1818.588281\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1799.873906\n",
            "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 1784.241563\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 1809.230625\n",
            "====> Epoch: 1 Average loss: 1820.7228\n",
            "====> Test set loss: 1826.2763\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1811.452656\n",
            "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 1813.932969\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 1804.663281\n",
            "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 1829.004531\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1821.543437\n",
            "====> Epoch: 2 Average loss: 1820.7424\n",
            "====> Test set loss: 1826.4750\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1827.175156\n",
            "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1807.851875\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1808.386719\n",
            "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 1816.398438\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 1805.667031\n",
            "====> Epoch: 3 Average loss: 1820.5755\n",
            "====> Test set loss: 1826.2224\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1799.898438\n",
            "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 1835.803750\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 1801.164531\n",
            "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1830.257500\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1851.865469\n",
            "====> Epoch: 4 Average loss: 1820.6126\n",
            "====> Test set loss: 1826.3628\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1831.892188\n",
            "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 1818.096406\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1819.788438\n",
            "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 1803.967344\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 1845.308750\n",
            "====> Epoch: 5 Average loss: 1820.4427\n",
            "====> Test set loss: 1826.2382\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1819.284219\n",
            "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 1827.311250\n",
            "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 1808.688594\n",
            "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 1782.251094\n",
            "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 1850.255156\n",
            "====> Epoch: 6 Average loss: 1820.2362\n",
            "====> Test set loss: 1826.6820\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1833.907656\n",
            "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 1808.056719\n",
            "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 1824.041406\n",
            "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 1825.874375\n",
            "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 1821.709531\n",
            "====> Epoch: 7 Average loss: 1820.2549\n",
            "====> Test set loss: 1828.0567\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1819.590469\n",
            "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 1802.132812\n",
            "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 1824.422188\n",
            "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 1823.976719\n",
            "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 1808.356875\n",
            "====> Epoch: 8 Average loss: 1820.1874\n",
            "====> Test set loss: 1826.1817\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1797.453438\n",
            "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 1818.256719\n",
            "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 1848.028750\n",
            "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 1825.925156\n",
            "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 1774.415937\n",
            "====> Epoch: 9 Average loss: 1820.1934\n",
            "====> Test set loss: 1825.9637\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1828.910000\n",
            "Train Epoch: 10 [10000/50000 (20%)]\tLoss: 1813.085313\n",
            "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 1851.076719\n",
            "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 1812.070781\n",
            "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 1821.795312\n",
            "====> Epoch: 10 Average loss: 1820.0583\n",
            "====> Test set loss: 1825.9391\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1854.484688\n",
            "Train Epoch: 11 [10000/50000 (20%)]\tLoss: 1819.281406\n",
            "Train Epoch: 11 [20000/50000 (40%)]\tLoss: 1846.546250\n",
            "Train Epoch: 11 [30000/50000 (60%)]\tLoss: 1838.007656\n",
            "Train Epoch: 11 [40000/50000 (80%)]\tLoss: 1815.142812\n",
            "====> Epoch: 11 Average loss: 1820.0610\n",
            "====> Test set loss: 1825.6602\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1771.010937\n",
            "Train Epoch: 12 [10000/50000 (20%)]\tLoss: 1865.180156\n",
            "Train Epoch: 12 [20000/50000 (40%)]\tLoss: 1846.082031\n",
            "Train Epoch: 12 [30000/50000 (60%)]\tLoss: 1874.557969\n",
            "Train Epoch: 12 [40000/50000 (80%)]\tLoss: 1801.656563\n",
            "====> Epoch: 12 Average loss: 1819.9374\n",
            "====> Test set loss: 1825.6849\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1831.993750\n",
            "Train Epoch: 13 [10000/50000 (20%)]\tLoss: 1846.909844\n",
            "Train Epoch: 13 [20000/50000 (40%)]\tLoss: 1795.999063\n",
            "Train Epoch: 13 [30000/50000 (60%)]\tLoss: 1798.604375\n",
            "Train Epoch: 13 [40000/50000 (80%)]\tLoss: 1839.892969\n",
            "====> Epoch: 13 Average loss: 1819.9127\n",
            "====> Test set loss: 1826.1399\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1856.260000\n",
            "Train Epoch: 14 [10000/50000 (20%)]\tLoss: 1823.607188\n",
            "Train Epoch: 14 [20000/50000 (40%)]\tLoss: 1838.825625\n",
            "Train Epoch: 14 [30000/50000 (60%)]\tLoss: 1814.218750\n",
            "Train Epoch: 14 [40000/50000 (80%)]\tLoss: 1811.818750\n",
            "====> Epoch: 14 Average loss: 1819.7665\n",
            "====> Test set loss: 1825.8259\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1814.486562\n",
            "Train Epoch: 15 [10000/50000 (20%)]\tLoss: 1803.366094\n",
            "Train Epoch: 15 [20000/50000 (40%)]\tLoss: 1792.817344\n",
            "Train Epoch: 15 [30000/50000 (60%)]\tLoss: 1798.158750\n",
            "Train Epoch: 15 [40000/50000 (80%)]\tLoss: 1806.005625\n",
            "====> Epoch: 15 Average loss: 1819.8065\n",
            "====> Test set loss: 1825.3743\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1818.529531\n",
            "Train Epoch: 16 [10000/50000 (20%)]\tLoss: 1809.926563\n",
            "Train Epoch: 16 [20000/50000 (40%)]\tLoss: 1817.264219\n",
            "Train Epoch: 16 [30000/50000 (60%)]\tLoss: 1773.215625\n",
            "Train Epoch: 16 [40000/50000 (80%)]\tLoss: 1817.895313\n",
            "====> Epoch: 16 Average loss: 1819.7672\n",
            "====> Test set loss: 1825.7254\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1840.105625\n",
            "Train Epoch: 17 [10000/50000 (20%)]\tLoss: 1830.562969\n",
            "Train Epoch: 17 [20000/50000 (40%)]\tLoss: 1842.179531\n",
            "Train Epoch: 17 [30000/50000 (60%)]\tLoss: 1786.933438\n",
            "Train Epoch: 17 [40000/50000 (80%)]\tLoss: 1782.803281\n",
            "====> Epoch: 17 Average loss: 1819.6211\n",
            "====> Test set loss: 1825.9140\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1794.652500\n",
            "Train Epoch: 18 [10000/50000 (20%)]\tLoss: 1822.054219\n",
            "Train Epoch: 18 [20000/50000 (40%)]\tLoss: 1844.147656\n",
            "Train Epoch: 18 [30000/50000 (60%)]\tLoss: 1845.624063\n",
            "Train Epoch: 18 [40000/50000 (80%)]\tLoss: 1810.314687\n",
            "====> Epoch: 18 Average loss: 1819.6077\n",
            "====> Test set loss: 1826.0067\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1823.938437\n",
            "Train Epoch: 19 [10000/50000 (20%)]\tLoss: 1860.040625\n",
            "Train Epoch: 19 [20000/50000 (40%)]\tLoss: 1845.924531\n",
            "Train Epoch: 19 [30000/50000 (60%)]\tLoss: 1831.293125\n",
            "Train Epoch: 19 [40000/50000 (80%)]\tLoss: 1833.392656\n",
            "====> Epoch: 19 Average loss: 1819.6538\n",
            "====> Test set loss: 1825.5848\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1794.793125\n",
            "Train Epoch: 20 [10000/50000 (20%)]\tLoss: 1852.277188\n",
            "Train Epoch: 20 [20000/50000 (40%)]\tLoss: 1799.797656\n",
            "Train Epoch: 20 [30000/50000 (60%)]\tLoss: 1798.122500\n",
            "Train Epoch: 20 [40000/50000 (80%)]\tLoss: 1847.079375\n",
            "====> Epoch: 20 Average loss: 1819.5018\n",
            "====> Test set loss: 1825.8940\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 1839.736250\n",
            "Train Epoch: 21 [10000/50000 (20%)]\tLoss: 1851.734219\n",
            "Train Epoch: 21 [20000/50000 (40%)]\tLoss: 1760.857344\n",
            "Train Epoch: 21 [30000/50000 (60%)]\tLoss: 1857.227969\n",
            "Train Epoch: 21 [40000/50000 (80%)]\tLoss: 1884.259687\n",
            "====> Epoch: 21 Average loss: 1819.4413\n",
            "====> Test set loss: 1825.5929\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 1851.708125\n",
            "Train Epoch: 22 [10000/50000 (20%)]\tLoss: 1806.369844\n",
            "Train Epoch: 22 [20000/50000 (40%)]\tLoss: 1827.996562\n",
            "Train Epoch: 22 [30000/50000 (60%)]\tLoss: 1822.057969\n",
            "Train Epoch: 22 [40000/50000 (80%)]\tLoss: 1804.413281\n",
            "====> Epoch: 22 Average loss: 1819.4204\n",
            "====> Test set loss: 1826.2750\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 1822.212812\n",
            "Train Epoch: 23 [10000/50000 (20%)]\tLoss: 1835.157344\n",
            "Train Epoch: 23 [20000/50000 (40%)]\tLoss: 1826.527344\n",
            "Train Epoch: 23 [30000/50000 (60%)]\tLoss: 1765.651719\n",
            "Train Epoch: 23 [40000/50000 (80%)]\tLoss: 1858.432344\n",
            "====> Epoch: 23 Average loss: 1819.3237\n",
            "====> Test set loss: 1826.3373\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 1847.402344\n",
            "Train Epoch: 24 [10000/50000 (20%)]\tLoss: 1801.771719\n",
            "Train Epoch: 24 [20000/50000 (40%)]\tLoss: 1818.459063\n",
            "Train Epoch: 24 [30000/50000 (60%)]\tLoss: 1783.161094\n",
            "Train Epoch: 24 [40000/50000 (80%)]\tLoss: 1799.504062\n",
            "====> Epoch: 24 Average loss: 1819.3075\n",
            "====> Test set loss: 1826.1895\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 1806.114063\n",
            "Train Epoch: 25 [10000/50000 (20%)]\tLoss: 1827.887031\n",
            "Train Epoch: 25 [20000/50000 (40%)]\tLoss: 1804.303594\n",
            "Train Epoch: 25 [30000/50000 (60%)]\tLoss: 1813.167969\n",
            "Train Epoch: 25 [40000/50000 (80%)]\tLoss: 1807.930625\n",
            "====> Epoch: 25 Average loss: 1819.2308\n",
            "====> Test set loss: 1825.5988\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 1855.882031\n",
            "Train Epoch: 26 [10000/50000 (20%)]\tLoss: 1806.282500\n",
            "Train Epoch: 26 [20000/50000 (40%)]\tLoss: 1805.120469\n",
            "Train Epoch: 26 [30000/50000 (60%)]\tLoss: 1810.813750\n",
            "Train Epoch: 26 [40000/50000 (80%)]\tLoss: 1809.735156\n",
            "====> Epoch: 26 Average loss: 1819.1382\n",
            "====> Test set loss: 1826.2822\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 1796.465469\n",
            "Train Epoch: 27 [10000/50000 (20%)]\tLoss: 1840.285156\n",
            "Train Epoch: 27 [20000/50000 (40%)]\tLoss: 1809.880156\n",
            "Train Epoch: 27 [30000/50000 (60%)]\tLoss: 1808.963438\n",
            "Train Epoch: 27 [40000/50000 (80%)]\tLoss: 1828.152969\n",
            "====> Epoch: 27 Average loss: 1819.2227\n",
            "====> Test set loss: 1826.0217\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 1792.943906\n",
            "Train Epoch: 28 [10000/50000 (20%)]\tLoss: 1819.860312\n",
            "Train Epoch: 28 [20000/50000 (40%)]\tLoss: 1834.680625\n",
            "Train Epoch: 28 [30000/50000 (60%)]\tLoss: 1838.894687\n",
            "Train Epoch: 28 [40000/50000 (80%)]\tLoss: 1837.124531\n",
            "====> Epoch: 28 Average loss: 1819.1791\n",
            "====> Test set loss: 1825.7622\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 1831.767969\n",
            "Train Epoch: 29 [10000/50000 (20%)]\tLoss: 1806.997813\n",
            "Train Epoch: 29 [20000/50000 (40%)]\tLoss: 1794.393750\n",
            "Train Epoch: 29 [30000/50000 (60%)]\tLoss: 1808.366875\n",
            "Train Epoch: 29 [40000/50000 (80%)]\tLoss: 1764.626875\n",
            "====> Epoch: 29 Average loss: 1819.0024\n",
            "====> Test set loss: 1826.4955\n",
            "Train Epoch: 30 [0/50000 (0%)]\tLoss: 1828.427969\n",
            "Train Epoch: 30 [10000/50000 (20%)]\tLoss: 1810.814063\n",
            "Train Epoch: 30 [20000/50000 (40%)]\tLoss: 1809.853750\n",
            "Train Epoch: 30 [30000/50000 (60%)]\tLoss: 1820.844687\n",
            "Train Epoch: 30 [40000/50000 (80%)]\tLoss: 1785.910000\n",
            "====> Epoch: 30 Average loss: 1819.0592\n",
            "====> Test set loss: 1826.5482\n",
            "Train Epoch: 31 [0/50000 (0%)]\tLoss: 1832.343906\n",
            "Train Epoch: 31 [10000/50000 (20%)]\tLoss: 1811.127187\n",
            "Train Epoch: 31 [20000/50000 (40%)]\tLoss: 1826.363437\n",
            "Train Epoch: 31 [30000/50000 (60%)]\tLoss: 1846.188906\n",
            "Train Epoch: 31 [40000/50000 (80%)]\tLoss: 1783.234844\n",
            "====> Epoch: 31 Average loss: 1819.1396\n",
            "====> Test set loss: 1826.9199\n",
            "Train Epoch: 32 [0/50000 (0%)]\tLoss: 1774.607656\n",
            "Train Epoch: 32 [10000/50000 (20%)]\tLoss: 1814.760156\n",
            "Train Epoch: 32 [20000/50000 (40%)]\tLoss: 1846.276406\n",
            "Train Epoch: 32 [30000/50000 (60%)]\tLoss: 1818.638750\n",
            "Train Epoch: 32 [40000/50000 (80%)]\tLoss: 1829.605000\n",
            "====> Epoch: 32 Average loss: 1818.9077\n",
            "====> Test set loss: 1826.1769\n",
            "Train Epoch: 33 [0/50000 (0%)]\tLoss: 1781.485312\n",
            "Train Epoch: 33 [10000/50000 (20%)]\tLoss: 1799.664687\n",
            "Train Epoch: 33 [20000/50000 (40%)]\tLoss: 1822.327031\n",
            "Train Epoch: 33 [30000/50000 (60%)]\tLoss: 1834.531406\n",
            "Train Epoch: 33 [40000/50000 (80%)]\tLoss: 1789.028906\n",
            "====> Epoch: 33 Average loss: 1818.9994\n",
            "====> Test set loss: 1825.8217\n",
            "Train Epoch: 34 [0/50000 (0%)]\tLoss: 1864.722188\n",
            "Train Epoch: 34 [10000/50000 (20%)]\tLoss: 1819.400938\n",
            "Train Epoch: 34 [20000/50000 (40%)]\tLoss: 1794.327500\n",
            "Train Epoch: 34 [30000/50000 (60%)]\tLoss: 1865.157187\n",
            "Train Epoch: 34 [40000/50000 (80%)]\tLoss: 1845.859688\n",
            "====> Epoch: 34 Average loss: 1818.8580\n",
            "====> Test set loss: 1825.9375\n",
            "Train Epoch: 35 [0/50000 (0%)]\tLoss: 1802.714688\n",
            "Train Epoch: 35 [10000/50000 (20%)]\tLoss: 1804.055625\n",
            "Train Epoch: 35 [20000/50000 (40%)]\tLoss: 1796.593437\n",
            "Train Epoch: 35 [30000/50000 (60%)]\tLoss: 1829.638125\n",
            "Train Epoch: 35 [40000/50000 (80%)]\tLoss: 1840.775312\n",
            "====> Epoch: 35 Average loss: 1818.8792\n",
            "====> Test set loss: 1825.5835\n",
            "Train Epoch: 36 [0/50000 (0%)]\tLoss: 1797.739844\n",
            "Train Epoch: 36 [10000/50000 (20%)]\tLoss: 1869.663906\n",
            "Train Epoch: 36 [20000/50000 (40%)]\tLoss: 1822.461562\n",
            "Train Epoch: 36 [30000/50000 (60%)]\tLoss: 1800.977500\n",
            "Train Epoch: 36 [40000/50000 (80%)]\tLoss: 1843.748125\n",
            "====> Epoch: 36 Average loss: 1818.9207\n",
            "====> Test set loss: 1826.8070\n",
            "Train Epoch: 37 [0/50000 (0%)]\tLoss: 1799.233438\n",
            "Train Epoch: 37 [10000/50000 (20%)]\tLoss: 1805.069531\n",
            "Train Epoch: 37 [20000/50000 (40%)]\tLoss: 1843.283750\n",
            "Train Epoch: 37 [30000/50000 (60%)]\tLoss: 1842.149531\n",
            "Train Epoch: 37 [40000/50000 (80%)]\tLoss: 1820.734688\n",
            "====> Epoch: 37 Average loss: 1818.7206\n",
            "====> Test set loss: 1825.7395\n",
            "Train Epoch: 38 [0/50000 (0%)]\tLoss: 1780.281563\n",
            "Train Epoch: 38 [10000/50000 (20%)]\tLoss: 1848.940469\n",
            "Train Epoch: 38 [20000/50000 (40%)]\tLoss: 1802.680469\n",
            "Train Epoch: 38 [30000/50000 (60%)]\tLoss: 1789.318906\n",
            "Train Epoch: 38 [40000/50000 (80%)]\tLoss: 1816.031250\n",
            "====> Epoch: 38 Average loss: 1818.7781\n",
            "====> Test set loss: 1825.8202\n",
            "Train Epoch: 39 [0/50000 (0%)]\tLoss: 1816.386094\n",
            "Train Epoch: 39 [10000/50000 (20%)]\tLoss: 1814.779531\n",
            "Train Epoch: 39 [20000/50000 (40%)]\tLoss: 1847.196406\n",
            "Train Epoch: 39 [30000/50000 (60%)]\tLoss: 1829.685469\n",
            "Train Epoch: 39 [40000/50000 (80%)]\tLoss: 1837.310937\n",
            "====> Epoch: 39 Average loss: 1818.6990\n",
            "====> Test set loss: 1826.3358\n",
            "Train Epoch: 40 [0/50000 (0%)]\tLoss: 1791.163906\n",
            "Train Epoch: 40 [10000/50000 (20%)]\tLoss: 1847.438594\n",
            "Train Epoch: 40 [20000/50000 (40%)]\tLoss: 1824.068281\n",
            "Train Epoch: 40 [30000/50000 (60%)]\tLoss: 1790.068750\n",
            "Train Epoch: 40 [40000/50000 (80%)]\tLoss: 1816.851719\n",
            "====> Epoch: 40 Average loss: 1818.6302\n",
            "====> Test set loss: 1826.0918\n",
            "Train Epoch: 41 [0/50000 (0%)]\tLoss: 1802.830156\n",
            "Train Epoch: 41 [10000/50000 (20%)]\tLoss: 1810.312969\n",
            "Train Epoch: 41 [20000/50000 (40%)]\tLoss: 1808.660938\n",
            "Train Epoch: 41 [30000/50000 (60%)]\tLoss: 1801.462812\n",
            "Train Epoch: 41 [40000/50000 (80%)]\tLoss: 1812.559531\n",
            "====> Epoch: 41 Average loss: 1818.7265\n",
            "====> Test set loss: 1825.9929\n",
            "Train Epoch: 42 [0/50000 (0%)]\tLoss: 1801.549687\n",
            "Train Epoch: 42 [10000/50000 (20%)]\tLoss: 1825.348906\n",
            "Train Epoch: 42 [20000/50000 (40%)]\tLoss: 1843.437969\n",
            "Train Epoch: 42 [30000/50000 (60%)]\tLoss: 1832.250313\n",
            "Train Epoch: 42 [40000/50000 (80%)]\tLoss: 1842.562187\n",
            "====> Epoch: 42 Average loss: 1818.6151\n",
            "====> Test set loss: 1825.8098\n",
            "Train Epoch: 43 [0/50000 (0%)]\tLoss: 1823.256094\n",
            "Train Epoch: 43 [10000/50000 (20%)]\tLoss: 1780.829375\n",
            "Train Epoch: 43 [20000/50000 (40%)]\tLoss: 1796.284375\n",
            "Train Epoch: 43 [30000/50000 (60%)]\tLoss: 1812.601406\n",
            "Train Epoch: 43 [40000/50000 (80%)]\tLoss: 1767.003281\n",
            "====> Epoch: 43 Average loss: 1818.4677\n",
            "====> Test set loss: 1825.9960\n",
            "Train Epoch: 44 [0/50000 (0%)]\tLoss: 1823.632500\n",
            "Train Epoch: 44 [10000/50000 (20%)]\tLoss: 1800.338594\n",
            "Train Epoch: 44 [20000/50000 (40%)]\tLoss: 1801.908906\n",
            "Train Epoch: 44 [30000/50000 (60%)]\tLoss: 1861.575313\n",
            "Train Epoch: 44 [40000/50000 (80%)]\tLoss: 1774.382812\n",
            "====> Epoch: 44 Average loss: 1818.5558\n",
            "====> Test set loss: 1826.1459\n",
            "Train Epoch: 45 [0/50000 (0%)]\tLoss: 1805.285469\n",
            "Train Epoch: 45 [10000/50000 (20%)]\tLoss: 1817.767656\n",
            "Train Epoch: 45 [20000/50000 (40%)]\tLoss: 1786.768125\n",
            "Train Epoch: 45 [30000/50000 (60%)]\tLoss: 1791.888906\n",
            "Train Epoch: 45 [40000/50000 (80%)]\tLoss: 1765.202031\n",
            "====> Epoch: 45 Average loss: 1818.4659\n",
            "====> Test set loss: 1825.9439\n",
            "Train Epoch: 46 [0/50000 (0%)]\tLoss: 1796.974844\n",
            "Train Epoch: 46 [10000/50000 (20%)]\tLoss: 1823.011563\n",
            "Train Epoch: 46 [20000/50000 (40%)]\tLoss: 1846.140312\n",
            "Train Epoch: 46 [30000/50000 (60%)]\tLoss: 1784.932031\n",
            "Train Epoch: 46 [40000/50000 (80%)]\tLoss: 1811.254531\n",
            "====> Epoch: 46 Average loss: 1818.5880\n",
            "====> Test set loss: 1826.0301\n",
            "Train Epoch: 47 [0/50000 (0%)]\tLoss: 1851.803437\n",
            "Train Epoch: 47 [10000/50000 (20%)]\tLoss: 1805.147500\n",
            "Train Epoch: 47 [20000/50000 (40%)]\tLoss: 1843.810937\n",
            "Train Epoch: 47 [30000/50000 (60%)]\tLoss: 1786.587812\n",
            "Train Epoch: 47 [40000/50000 (80%)]\tLoss: 1797.342813\n",
            "====> Epoch: 47 Average loss: 1818.3908\n",
            "====> Test set loss: 1826.1908\n",
            "Train Epoch: 48 [0/50000 (0%)]\tLoss: 1797.785000\n",
            "Train Epoch: 48 [10000/50000 (20%)]\tLoss: 1870.463281\n",
            "Train Epoch: 48 [20000/50000 (40%)]\tLoss: 1799.724375\n",
            "Train Epoch: 48 [30000/50000 (60%)]\tLoss: 1816.824531\n",
            "Train Epoch: 48 [40000/50000 (80%)]\tLoss: 1841.627656\n",
            "====> Epoch: 48 Average loss: 1818.4456\n",
            "====> Test set loss: 1826.3044\n",
            "Train Epoch: 49 [0/50000 (0%)]\tLoss: 1775.337031\n",
            "Train Epoch: 49 [10000/50000 (20%)]\tLoss: 1848.310781\n",
            "Train Epoch: 49 [20000/50000 (40%)]\tLoss: 1813.299375\n",
            "Train Epoch: 49 [30000/50000 (60%)]\tLoss: 1826.357344\n",
            "Train Epoch: 49 [40000/50000 (80%)]\tLoss: 1855.251563\n",
            "====> Epoch: 49 Average loss: 1818.3620\n",
            "====> Test set loss: 1826.1433\n",
            "Train Epoch: 50 [0/50000 (0%)]\tLoss: 1810.367656\n",
            "Train Epoch: 50 [10000/50000 (20%)]\tLoss: 1785.281406\n",
            "Train Epoch: 50 [20000/50000 (40%)]\tLoss: 1823.326250\n",
            "Train Epoch: 50 [30000/50000 (60%)]\tLoss: 1817.989531\n",
            "Train Epoch: 50 [40000/50000 (80%)]\tLoss: 1810.790156\n",
            "====> Epoch: 50 Average loss: 1818.3715\n",
            "====> Test set loss: 1826.0950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBT-Ex-etTLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
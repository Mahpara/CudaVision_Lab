{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBwKptwQHIaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGUO7pJKHQYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f6079eb-ac6f-4c06-a5ad-08bcf4f019ef"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(2805)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc10a3290c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91rYjcw1HVkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "## Make Iterable Train and Test Set\n",
        "batch_size = 100\n",
        "n_iters = 6000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY71K5IBHWUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OurLSTM(nn.Module):\n",
        "    def __init__(self,input_dim, hidden_dim,output_dim):\n",
        "        super(OurLSTM,self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "\n",
        "        # ====   Weights and Bias   ===========\n",
        "        self.w_ii = Parameter(torch.Tensor(self.input_dim,self.hidden_dim))\n",
        "        self.w_hi = Parameter(torch.Tensor(self.hidden_dim,self.hidden_dim))\n",
        "        self.w_if = Parameter(torch.Tensor(self.input_dim,self.hidden_dim))\n",
        "        self.w_hf = Parameter(torch.Tensor(self.hidden_dim,self.hidden_dim))\n",
        "        self.w_ic = Parameter(torch.Tensor(self.input_dim,self.hidden_dim))\n",
        "        self.w_hc = Parameter(torch.Tensor(self.hidden_dim,self.hidden_dim))\n",
        "        self.w_io = Parameter(torch.Tensor(self.input_dim,self.hidden_dim))\n",
        "        self.w_ho = Parameter(torch.Tensor(self.hidden_dim,self.hidden_dim))\n",
        "\n",
        "        self.b_i = Parameter(torch.Tensor(self.hidden_dim))\n",
        "        self.b_f = Parameter(torch.Tensor(self.hidden_dim))\n",
        "        self.b_c = Parameter(torch.Tensor(self.hidden_dim))\n",
        "        self.b_o = Parameter(torch.Tensor(self.hidden_dim))\n",
        "\n",
        "        # ===  Fully Connected Layer   ======\n",
        "        self.fc = nn.Linear(100,self.output_dim)\n",
        "\n",
        "        self.custom_weight_initializer()\n",
        "        #self.init_params()\n",
        "\n",
        "    def forward(self,x,init_states=None):\n",
        "        batch_size,seq,_ = x.size()\n",
        "        hidden_seq = []\n",
        "        if init_states is None:\n",
        "            h_t, c_t = (torch.zeros(x.size(0), self.hidden_dim),\n",
        "                        torch.zeros(x.size(0), self.hidden_dim))\n",
        "        else:\n",
        "            h_t, c_t = init_states\n",
        "        for i in range(seq):\n",
        "            x_t = x[:,i,:]\n",
        "            i_t = self.input_gate(h_t,x_t)\n",
        "            f_t = self.forget_gate(h_t,x_t,c_t)\n",
        "            c_t = self.update_gate(i_t,f_t)\n",
        "            output, h_t = self.output_gate(h_t,x_t,c_t)\n",
        "            hidden_seq.append(h_t.unsqueeze(0))\n",
        "\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "        #print(\"Concatenated Hidden seq size: \", hidden_seq.size())\n",
        "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
        "        hidden_seq = hidden_seq.transpose(0, 1).contiguous() #contigious-> GPU parallel computing, for memory allocation\n",
        "        #print(\"Transposed Hidden seq Size: \",hidden_seq.size())\n",
        "        \n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
        "        out = hidden_seq[:,-1,:]\n",
        "        fc_output = self.fc(out)\n",
        "        \n",
        "        return fc_output\n",
        "\n",
        "    def create_rand_array(self,a, b, array_size):\n",
        "        \n",
        "        return torch.rand(array_size) * (b - a) + a\n",
        "\n",
        "    def custom_weight_initializer(self):\n",
        "        for param in self.parameters():\n",
        "            if param.data.ndimension() >= 2:\n",
        "                param.data = self.create_rand_array(-0.2,0.2,param.data.size())\n",
        "            else: \n",
        "                param.data = torch.zeros(param.data.size())\n",
        "\n",
        "    def init_params(self):\n",
        "        for param in self.parameters():\n",
        "            if param.data.ndimension() >= 2: \n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            else: \n",
        "                nn.init.zeros_(param.data)\n",
        "\n",
        "    def input_gate(self,h_prev, x):\n",
        "        i_t = torch.sigmoid(x @ self.w_ii + h_prev @ self.w_hi + self.b_i)\n",
        "        candidate = torch.tanh(x @ self.w_ic + h_prev @ self.w_hc + self.b_c)\n",
        "        out = torch.mul(i_t, candidate)\n",
        "        return out\n",
        "\n",
        "    def forget_gate(self,h_prev, x, c_prev):\n",
        "        f_t = torch.sigmoid(x @ self.w_if + h_prev @ self.w_hf + self.b_f)\n",
        "        out = torch.mul(f_t, c_prev)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def update_gate(self,in_out, f_out):\n",
        "        c_t = in_out + f_out  \n",
        "        return c_t\n",
        "\n",
        "    def output_gate(self,h_prev, x, c_t):\n",
        "        o_out = torch.sigmoid(x @ self.w_io + h_prev @ self.w_ho + self.b_o)\n",
        "        h_t = torch.mul(o_out, torch.tanh(c_t))\n",
        "        \n",
        "        return o_out, h_t\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGOYWTGDHqVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## =======   T R A  I N I N G  &  T E S T I N G    ==============\n",
        "def train_and_test(model,optimizer,criterion,train_loader,test_loader):\n",
        "    model.train()\n",
        "    # Number of steps to unroll\n",
        "    seq_dim = 28\n",
        "    iter = 0\n",
        "    loss_list = []\n",
        "    acc_list  =[]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            \n",
        "            #print(\"images.size()\",images.size()) #[100,1,28,28]\n",
        "            images = images.view(-1, seq_dim, input_dim)\n",
        "            #print(\"images.size()\",images.size()) #[100,28,28]\n",
        "            # Clear gradients w.r.t. parameters\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass to get output/logits\n",
        "            # outputs.size() --> 100, 10\n",
        "            outputs = model(images)\n",
        "    \n",
        "            # Calculate Loss: softmax --> cross entropy loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_list.append(loss.item())\n",
        "            # Getting gradients w.r.t. parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            iter += 1\n",
        "\n",
        "            if iter % 500 == 0:\n",
        "                # Calculate Accuracy\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                model.eval() # weights gulo fridge kore dicchi, jate wieght update na hoy\n",
        "                with torch.no_grad(): #grad off kore dichchi, grad_requires = false kore dichchi\n",
        "                    # Iterate through test dataset\n",
        "                    for images, labels in test_loader:\n",
        "                        # Resize images\n",
        "                        images = images.view(-1, seq_dim, input_dim)\n",
        "\n",
        "                        # Forward pass only to get logits/output\n",
        "                        outputs = model(images)\n",
        "\n",
        "                        # Get predictions from the maximum value\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                        # Total number of labels\n",
        "                        total += labels.size(0)\n",
        "\n",
        "                        # Total correct predictions\n",
        "                        correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    accuracy = 100 * correct / total\n",
        "                    acc_list.append(accuracy)\n",
        "\n",
        "                # Print Loss\n",
        "                print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
        "\n",
        "        \n",
        "    return loss_list, acc_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov-taiu2HyvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "31063e0a-d3ad-4b98-a26f-ba9e5825ff4b"
      },
      "source": [
        "## Instantiate the LSTM model\n",
        "input_dim = 28\n",
        "hidden_dim = 100\n",
        "layer_dim = 1\n",
        "output_dim = 10\n",
        "model = OurLSTM(input_dim,hidden_dim,output_dim)\n",
        "\n",
        "\n",
        "print(\"Number of parameters in the LSTM : \", len(list(model.parameters()))) \n",
        "for name, params in model.named_parameters():\n",
        "    print(name, params.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in the LSTM :  14\n",
            "w_ii torch.Size([28, 100])\n",
            "w_hi torch.Size([100, 100])\n",
            "w_if torch.Size([28, 100])\n",
            "w_hf torch.Size([100, 100])\n",
            "w_ic torch.Size([28, 100])\n",
            "w_hc torch.Size([100, 100])\n",
            "w_io torch.Size([28, 100])\n",
            "w_ho torch.Size([100, 100])\n",
            "b_i torch.Size([100])\n",
            "b_f torch.Size([100])\n",
            "b_c torch.Size([100])\n",
            "b_o torch.Size([100])\n",
            "fc.weight torch.Size([10, 100])\n",
            "fc.bias torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG57exr6H3cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "741b711f-c341-44e4-bad8-1d7d939087b5"
      },
      "source": [
        "# ========      Training & Testing ===============\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_list, acc_list = train_and_test(model,optimizer,criterion,train_loader,test_loader)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 0.6464361548423767. Accuracy: 84.77\n",
            "Iteration: 1000. Loss: 0.1687658280134201. Accuracy: 93.61\n",
            "Iteration: 1500. Loss: 0.3036350905895233. Accuracy: 94.21\n",
            "Iteration: 2000. Loss: 0.08583038300275803. Accuracy: 95.58\n",
            "Iteration: 2500. Loss: 0.06993672251701355. Accuracy: 96.89\n",
            "Iteration: 3000. Loss: 0.1766757220029831. Accuracy: 96.24\n",
            "Iteration: 3500. Loss: 0.062183357775211334. Accuracy: 97.0\n",
            "Iteration: 4000. Loss: 0.1050967201590538. Accuracy: 97.01\n",
            "Iteration: 4500. Loss: 0.11175236105918884. Accuracy: 97.5\n",
            "Iteration: 5000. Loss: 0.06583315134048462. Accuracy: 97.53\n",
            "Iteration: 5500. Loss: 0.10004343837499619. Accuracy: 97.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UAdYLVZhNYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}